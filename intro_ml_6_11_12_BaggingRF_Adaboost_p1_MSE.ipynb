{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 7)\n",
    "plt.rcParams['font.size'] = 22"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model\n",
    "\n",
    "- Secara ringkas, Ensemble Model adalah membuat prediksi dari hasil agregasi beberapa model.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1vXS4YK29ogq1nsc9sMHj5KAfpuhEbvw9\">\n",
    "\n",
    "- Ensemble model memanfaatkan model satu sama lain untuk membandingkan dan mengkoreksi hasil prediksi\n",
    "\n",
    "- Sehingga didapat peningkatan performa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273.0   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273.0   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273.0   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273.0   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  target  \n",
       "0       15.3  396.90   4.98    24.0  \n",
       "1       17.8  396.90   9.14    21.6  \n",
       "2       17.8  392.83   4.03    34.7  \n",
       "3       18.7  394.63   2.94    33.4  \n",
       "4       18.7  396.90   5.33    36.2  \n",
       "..       ...     ...    ...     ...  \n",
       "501     21.0  391.99   9.67    22.4  \n",
       "502     21.0  396.90   9.08    20.6  \n",
       "503     21.0  396.90   5.64    23.9  \n",
       "504     21.0  393.45   6.48    22.0  \n",
       "505     21.0  396.90   7.88    11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "data = pd.read_csv(\"data/boston_housing.csv\")\n",
    "data = data.rename(columns={'MEDV': 'target'})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns = \"target\")\n",
    "y = data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24.0\n",
       "1    21.6\n",
       "2    34.7\n",
       "3    33.4\n",
       "4    36.2\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train-test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (102, 13)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Buat & Fit scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>-0.401149</td>\n",
       "      <td>3.653859</td>\n",
       "      <td>-1.226095</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>-1.199016</td>\n",
       "      <td>2.231987</td>\n",
       "      <td>-1.278274</td>\n",
       "      <td>0.623686</td>\n",
       "      <td>-0.636934</td>\n",
       "      <td>-1.095990</td>\n",
       "      <td>-1.753696</td>\n",
       "      <td>0.388482</td>\n",
       "      <td>-1.266398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0.702723</td>\n",
       "      <td>-0.486534</td>\n",
       "      <td>0.995482</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>1.587329</td>\n",
       "      <td>0.176596</td>\n",
       "      <td>1.008537</td>\n",
       "      <td>-0.806000</td>\n",
       "      <td>1.675027</td>\n",
       "      <td>1.530409</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>0.313998</td>\n",
       "      <td>0.940407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-0.389296</td>\n",
       "      <td>-0.486534</td>\n",
       "      <td>-1.028718</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>-0.391243</td>\n",
       "      <td>-1.008059</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>-0.557330</td>\n",
       "      <td>-0.521336</td>\n",
       "      <td>-0.668160</td>\n",
       "      <td>-0.868429</td>\n",
       "      <td>0.433478</td>\n",
       "      <td>0.261930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.391244</td>\n",
       "      <td>-0.486534</td>\n",
       "      <td>-1.195840</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>-0.950404</td>\n",
       "      <td>0.487675</td>\n",
       "      <td>-0.399281</td>\n",
       "      <td>-0.136278</td>\n",
       "      <td>-0.868130</td>\n",
       "      <td>-0.787002</td>\n",
       "      <td>-0.216127</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>-0.867459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>-0.403599</td>\n",
       "      <td>2.782197</td>\n",
       "      <td>-1.035921</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>-1.251491</td>\n",
       "      <td>-0.559197</td>\n",
       "      <td>-0.763742</td>\n",
       "      <td>1.654751</td>\n",
       "      <td>-0.752532</td>\n",
       "      <td>0.359819</td>\n",
       "      <td>1.228256</td>\n",
       "      <td>0.433478</td>\n",
       "      <td>0.277382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.395821</td>\n",
       "      <td>-0.486534</td>\n",
       "      <td>-1.195840</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>-0.950404</td>\n",
       "      <td>2.185112</td>\n",
       "      <td>-1.146068</td>\n",
       "      <td>-0.136278</td>\n",
       "      <td>-0.868130</td>\n",
       "      <td>-0.787002</td>\n",
       "      <td>-0.216127</td>\n",
       "      <td>0.396673</td>\n",
       "      <td>-1.300111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.149849</td>\n",
       "      <td>-0.486534</td>\n",
       "      <td>0.995482</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>0.503416</td>\n",
       "      <td>0.287391</td>\n",
       "      <td>0.879904</td>\n",
       "      <td>-0.693513</td>\n",
       "      <td>1.675027</td>\n",
       "      <td>1.530409</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>0.425942</td>\n",
       "      <td>0.822411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>-0.365143</td>\n",
       "      <td>-0.486534</td>\n",
       "      <td>-0.548961</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>-0.537485</td>\n",
       "      <td>-0.341868</td>\n",
       "      <td>-0.681559</td>\n",
       "      <td>0.437816</td>\n",
       "      <td>-0.521336</td>\n",
       "      <td>-0.721639</td>\n",
       "      <td>0.529361</td>\n",
       "      <td>0.433478</td>\n",
       "      <td>-0.719964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0.641524</td>\n",
       "      <td>-0.486534</td>\n",
       "      <td>0.995482</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>1.243229</td>\n",
       "      <td>-1.059195</td>\n",
       "      <td>1.108585</td>\n",
       "      <td>-1.032987</td>\n",
       "      <td>1.675027</td>\n",
       "      <td>1.530409</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>0.433478</td>\n",
       "      <td>1.513530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>0.113900</td>\n",
       "      <td>-0.486534</td>\n",
       "      <td>0.995482</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>1.398074</td>\n",
       "      <td>-3.864583</td>\n",
       "      <td>0.676235</td>\n",
       "      <td>-1.017626</td>\n",
       "      <td>1.675027</td>\n",
       "      <td>1.530409</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>-0.027403</td>\n",
       "      <td>-0.801438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "203 -0.401149  3.653859 -1.226095 -0.245698 -1.199016  2.231987 -1.278274   \n",
       "441  0.702723 -0.486534  0.995482 -0.245698  1.587329  0.176596  1.008537   \n",
       "172 -0.389296 -0.486534 -1.028718 -0.245698 -0.391243 -1.008059  0.697674   \n",
       "95  -0.391244 -0.486534 -1.195840 -0.245698 -0.950404  0.487675 -0.399281   \n",
       "54  -0.403599  2.782197 -1.035921 -0.245698 -1.251491 -0.559197 -0.763742   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "98  -0.395821 -0.486534 -1.195840 -0.245698 -0.950404  2.185112 -1.146068   \n",
       "476  0.149849 -0.486534  0.995482 -0.245698  0.503416  0.287391  0.879904   \n",
       "322 -0.365143 -0.486534 -0.548961 -0.245698 -0.537485 -0.341868 -0.681559   \n",
       "382  0.641524 -0.486534  0.995482 -0.245698  1.243229 -1.059195  1.108585   \n",
       "365  0.113900 -0.486534  0.995482 -0.245698  1.398074 -3.864583  0.676235   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "203  0.623686 -0.636934 -1.095990 -1.753696  0.388482 -1.266398  \n",
       "441 -0.806000  1.675027  1.530409  0.808919  0.313998  0.940407  \n",
       "172 -0.557330 -0.521336 -0.668160 -0.868429  0.433478  0.261930  \n",
       "95  -0.136278 -0.868130 -0.787002 -0.216127  0.008419 -0.867459  \n",
       "54   1.654751 -0.752532  0.359819  1.228256  0.433478  0.277382  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "98  -0.136278 -0.868130 -0.787002 -0.216127  0.396673 -1.300111  \n",
       "476 -0.693513  1.675027  1.530409  0.808919  0.425942  0.822411  \n",
       "322  0.437816 -0.521336 -0.721639  0.529361  0.433478 -0.719964  \n",
       "382 -1.032987  1.675027  1.530409  0.808919  0.433478  1.513530  \n",
       "365 -1.017626  1.675027  1.530409  0.808919 -0.027403 -0.801438  \n",
       "\n",
       "[404 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform data\n",
    "X_train_clean = scaler.transform(X_train)\n",
    "X_train_clean = pd.DataFrame(X_train_clean,\n",
    "                             columns = X_train.columns,\n",
    "                             index = X_train.index)\n",
    "\n",
    "X_train_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_transform(X, scaler = None):\n",
    "    \"\"\"\n",
    "    Fungsi untuk melakukan standardisasi\n",
    "    :param X: <pandas DataFrame> sampel data\n",
    "    :param scaler: <sklearn object> scaler, default None\n",
    "    :return X_scaled: <pandas Dataframe> sampel data OHE\n",
    "    :param scaler: <sklearn object> scaler, default None\n",
    "    \"\"\"\n",
    "    if scaler != None:\n",
    "        pass\n",
    "    else:\n",
    "        # Buat & fit encoder\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "\n",
    "    # Tranform data\n",
    "    X_scaled = scaler.transform(X)\n",
    "    X_scaled = pd.DataFrame(X_scaled,\n",
    "                            columns = X.columns,\n",
    "                            index = X.index)\n",
    "    \n",
    "    return X_scaled, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>-0.401149</td>\n",
       "      <td>3.653859</td>\n",
       "      <td>-1.226095</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>-1.199016</td>\n",
       "      <td>2.231987</td>\n",
       "      <td>-1.278274</td>\n",
       "      <td>0.623686</td>\n",
       "      <td>-0.636934</td>\n",
       "      <td>-1.095990</td>\n",
       "      <td>-1.753696</td>\n",
       "      <td>0.388482</td>\n",
       "      <td>-1.266398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0.702723</td>\n",
       "      <td>-0.486534</td>\n",
       "      <td>0.995482</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>1.587329</td>\n",
       "      <td>0.176596</td>\n",
       "      <td>1.008537</td>\n",
       "      <td>-0.806000</td>\n",
       "      <td>1.675027</td>\n",
       "      <td>1.530409</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>0.313998</td>\n",
       "      <td>0.940407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-0.389296</td>\n",
       "      <td>-0.486534</td>\n",
       "      <td>-1.028718</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>-0.391243</td>\n",
       "      <td>-1.008059</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>-0.557330</td>\n",
       "      <td>-0.521336</td>\n",
       "      <td>-0.668160</td>\n",
       "      <td>-0.868429</td>\n",
       "      <td>0.433478</td>\n",
       "      <td>0.261930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.391244</td>\n",
       "      <td>-0.486534</td>\n",
       "      <td>-1.195840</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>-0.950404</td>\n",
       "      <td>0.487675</td>\n",
       "      <td>-0.399281</td>\n",
       "      <td>-0.136278</td>\n",
       "      <td>-0.868130</td>\n",
       "      <td>-0.787002</td>\n",
       "      <td>-0.216127</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>-0.867459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>-0.403599</td>\n",
       "      <td>2.782197</td>\n",
       "      <td>-1.035921</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>-1.251491</td>\n",
       "      <td>-0.559197</td>\n",
       "      <td>-0.763742</td>\n",
       "      <td>1.654751</td>\n",
       "      <td>-0.752532</td>\n",
       "      <td>0.359819</td>\n",
       "      <td>1.228256</td>\n",
       "      <td>0.433478</td>\n",
       "      <td>0.277382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "203 -0.401149  3.653859 -1.226095 -0.245698 -1.199016  2.231987 -1.278274   \n",
       "441  0.702723 -0.486534  0.995482 -0.245698  1.587329  0.176596  1.008537   \n",
       "172 -0.389296 -0.486534 -1.028718 -0.245698 -0.391243 -1.008059  0.697674   \n",
       "95  -0.391244 -0.486534 -1.195840 -0.245698 -0.950404  0.487675 -0.399281   \n",
       "54  -0.403599  2.782197 -1.035921 -0.245698 -1.251491 -0.559197 -0.763742   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "203  0.623686 -0.636934 -1.095990 -1.753696  0.388482 -1.266398  \n",
       "441 -0.806000  1.675027  1.530409  0.808919  0.313998  0.940407  \n",
       "172 -0.557330 -0.521336 -0.668160 -0.868429  0.433478  0.261930  \n",
       "95  -0.136278 -0.868130 -0.787002 -0.216127  0.008419 -0.867459  \n",
       "54   1.654751 -0.752532  0.359819  1.228256  0.433478  0.277382  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean, scaler = scaler_transform(X = X_train)\n",
    "X_train_clean.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test(X, scaler):  \n",
    "    # Scaled data\n",
    "    X_clean, _ = scaler_transform(X = X,\n",
    "                                  scaler = scaler)\n",
    "    \n",
    "    return X_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>51.13580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>5.757</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.4130</td>\n",
       "      <td>24</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>2.60</td>\n",
       "      <td>10.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.05735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4490</td>\n",
       "      <td>6.630</td>\n",
       "      <td>56.1</td>\n",
       "      <td>4.4377</td>\n",
       "      <td>3</td>\n",
       "      <td>247.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>392.30</td>\n",
       "      <td>6.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.03578</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4429</td>\n",
       "      <td>7.820</td>\n",
       "      <td>64.5</td>\n",
       "      <td>4.6947</td>\n",
       "      <td>5</td>\n",
       "      <td>216.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>387.31</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>12.04820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>5.648</td>\n",
       "      <td>87.6</td>\n",
       "      <td>1.9512</td>\n",
       "      <td>24</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>291.55</td>\n",
       "      <td>14.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.03150</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4030</td>\n",
       "      <td>6.975</td>\n",
       "      <td>15.3</td>\n",
       "      <td>7.6534</td>\n",
       "      <td>3</td>\n",
       "      <td>402.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM    ZN  INDUS  CHAS     NOX     RM    AGE     DIS  RAD    TAX  \\\n",
       "410  51.13580   0.0  18.10     0  0.5970  5.757  100.0  1.4130   24  666.0   \n",
       "85    0.05735   0.0   4.49     0  0.4490  6.630   56.1  4.4377    3  247.0   \n",
       "280   0.03578  20.0   3.33     0  0.4429  7.820   64.5  4.6947    5  216.0   \n",
       "422  12.04820   0.0  18.10     0  0.6140  5.648   87.6  1.9512   24  666.0   \n",
       "199   0.03150  95.0   1.47     0  0.4030  6.975   15.3  7.6534    3  402.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "410     20.2    2.60  10.11  \n",
       "85      18.5  392.30   6.53  \n",
       "280     14.9  387.31   3.76  \n",
       "422     20.2  291.55  14.10  \n",
       "199     17.0  396.90   4.56  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>5.420728</td>\n",
       "      <td>-0.486534</td>\n",
       "      <td>0.995482</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>0.357173</td>\n",
       "      <td>-0.745275</td>\n",
       "      <td>1.108585</td>\n",
       "      <td>-1.111381</td>\n",
       "      <td>1.675027</td>\n",
       "      <td>1.530409</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>-3.872802</td>\n",
       "      <td>-0.381428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-0.398615</td>\n",
       "      <td>-0.486534</td>\n",
       "      <td>-0.965327</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>-0.915994</td>\n",
       "      <td>0.494777</td>\n",
       "      <td>-0.460024</td>\n",
       "      <td>0.305098</td>\n",
       "      <td>-0.752532</td>\n",
       "      <td>-0.959322</td>\n",
       "      <td>0.016838</td>\n",
       "      <td>0.383239</td>\n",
       "      <td>-0.884316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>-0.401072</td>\n",
       "      <td>0.385128</td>\n",
       "      <td>-1.132449</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>-0.968469</td>\n",
       "      <td>2.185112</td>\n",
       "      <td>-0.159880</td>\n",
       "      <td>0.425453</td>\n",
       "      <td>-0.521336</td>\n",
       "      <td>-1.143527</td>\n",
       "      <td>-1.660510</td>\n",
       "      <td>0.328742</td>\n",
       "      <td>-1.273421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0.967497</td>\n",
       "      <td>-0.486534</td>\n",
       "      <td>0.995482</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>0.503416</td>\n",
       "      <td>-0.900104</td>\n",
       "      <td>0.665515</td>\n",
       "      <td>-0.859340</td>\n",
       "      <td>1.675027</td>\n",
       "      <td>1.530409</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>-0.717084</td>\n",
       "      <td>0.179052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>-0.401560</td>\n",
       "      <td>3.653859</td>\n",
       "      <td>-1.400421</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>-1.311708</td>\n",
       "      <td>0.984832</td>\n",
       "      <td>-1.917867</td>\n",
       "      <td>1.811024</td>\n",
       "      <td>-0.752532</td>\n",
       "      <td>-0.038300</td>\n",
       "      <td>-0.682057</td>\n",
       "      <td>0.433478</td>\n",
       "      <td>-1.161044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "410  5.420728 -0.486534  0.995482 -0.245698  0.357173 -0.745275  1.108585   \n",
       "85  -0.398615 -0.486534 -0.965327 -0.245698 -0.915994  0.494777 -0.460024   \n",
       "280 -0.401072  0.385128 -1.132449 -0.245698 -0.968469  2.185112 -0.159880   \n",
       "422  0.967497 -0.486534  0.995482 -0.245698  0.503416 -0.900104  0.665515   \n",
       "199 -0.401560  3.653859 -1.400421 -0.245698 -1.311708  0.984832 -1.917867   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "410 -1.111381  1.675027  1.530409  0.808919 -3.872802 -0.381428  \n",
       "85   0.305098 -0.752532 -0.959322  0.016838  0.383239 -0.884316  \n",
       "280  0.425453 -0.521336 -1.143527 -1.660510  0.328742 -1.273421  \n",
       "422 -0.859340  1.675027  1.530409  0.808919 -0.717084  0.179052  \n",
       "199  1.811024 -0.752532 -0.038300 -0.682057  0.433478 -1.161044  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_clean = prepare_test(X = X_test, \n",
    "                            scaler = scaler)\n",
    "\n",
    "X_test_clean.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.37475247524753"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_baseline = y_train.mean()\n",
    "y_pred_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84.72074870110772, 83.35052289664024)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_train_baseline = mean_squared_error(y_train, y_pred_baseline * np.ones(len(y_train)))\n",
    "mse_test_baseline = mean_squared_error(y_test, y_pred_baseline * np.ones(len(y_test)))\n",
    "\n",
    "mse_train_baseline, mse_test_baseline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Decision Tree\n",
    "\n",
    "Lakukan gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"max_depth\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "\n",
    "# Buat gridsearch\n",
    "tree = DecisionTreeRegressor(random_state = 123)\n",
    "\n",
    "tree_cv = GridSearchCV(estimator = tree,\n",
    "                       param_grid = params,\n",
    "                       cv = 5,\n",
    "                       scoring = \"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(random_state=123),\n",
       "             param_grid={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit grid search cv\n",
    "tree_cv.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best params\n",
    "tree_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=4, random_state=123)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit the bagging tree\n",
    "tree = DecisionTreeRegressor(max_depth = tree_cv.best_params_[\"max_depth\"],\n",
    "                             random_state = 123)\n",
    "\n",
    "tree.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train :9.6612\n",
      "MSE CV    :25.1069\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred_train = tree.predict(X_train_clean)\n",
    "\n",
    "# MSE\n",
    "mse_train_dt = mean_squared_error(y_train, y_pred_train)\n",
    "mse_cv_dt = -tree_cv.best_score_\n",
    "\n",
    "print(f\"MSE Train :{mse_train_dt:.4f}\")\n",
    "print(f\"MSE CV    :{mse_cv_dt:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Bagging Method\n",
    "1. Membuat $B$-sampel bootstrap\n",
    "2. Membuat $B$-model decision tree untuk masing-masing sampel\n",
    "3. Setiap model melakukan prediksi.\n",
    "4. Melakukan agregasi dari setiap hasil prediksi.\n",
    "    - Regresi menggunakan rata-rata\n",
    "    - Klasifikasi menggunakan majority vote\n",
    "1. Membuat $B$-sampel bootstrap\n",
    "2. Membuat $B$-model decision tree untuk masing-masing sampel\n",
    "3. Setiap model melakukan prediksi.\n",
    "4. Melakukan agregasi dari setiap hasil prediksi.\n",
    "    - Regresi menggunakan rata-rata\n",
    "    - Klasifikasi menggunakan majority vote"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi Bagging\n",
    "def bagging(X_train, y_train, B):\n",
    "    \"\"\"\n",
    "    Fungsi untuk membuat model bagging\n",
    "    :param X_train: <pandas Dataframe> sampel input\n",
    "    :param y_train: <pandas Dataframe> sampel output\n",
    "    :param B: <int> jumlah bootstrap sample\n",
    "    :return trees: <list> kumpulan tree\n",
    "    \"\"\"\n",
    "    N = len(X_train)\n",
    "    trees = []\n",
    "\n",
    "    for b in range(B):\n",
    "        # Buat bootstrap\n",
    "        sample = np.random.choice(X_train.index,\n",
    "                                  size = N,\n",
    "                                  replace = True)\n",
    "        \n",
    "        X_train_b = X_train.loc[sample]\n",
    "        y_train_b = y_train.loc[sample]\n",
    "\n",
    "        # Buat model\n",
    "        tree = DecisionTreeRegressor()\n",
    "        tree.fit(X_train_b, y_train_b)\n",
    "\n",
    "        # Append tree\n",
    "        trees.append(tree)\n",
    "\n",
    "    return trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeRegressor(),\n",
       " DecisionTreeRegressor(),\n",
       " DecisionTreeRegressor(),\n",
       " DecisionTreeRegressor(),\n",
       " DecisionTreeRegressor()]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_mdl = bagging(X_train = X_train_clean, \n",
    "                      y_train = y_train, \n",
    "                      B = 5)\n",
    "\n",
    "bagging_mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi predict\n",
    "def predict_bagging(estimator, X):\n",
    "    \"\"\"\n",
    "    Fungsi untuk melakukan prediksi\n",
    "    :param estimator: <list> list model\n",
    "    :param X: <pandas Dataframe> sampel input\n",
    "    :param y_pred: <pandas Dataframe> prediksi sampel output\n",
    "    \"\"\"\n",
    "    B = len(estimator)\n",
    "    N = X.shape[0]\n",
    "    y_pred_list = np.zeros((B, N))\n",
    "\n",
    "    for i, tree in enumerate(estimator):\n",
    "        # Predict\n",
    "        y_pred_list[i] = tree.predict(X)\n",
    "\n",
    "    # Average\n",
    "    y_pred = np.mean(y_pred_list, axis = 0)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred_train = predict_bagging(estimator = bagging_mdl,\n",
    "                               X = X_train_clean)\n",
    "y_pred_test = predict_bagging(estimator = bagging_mdl,\n",
    "                              X = X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.1670643564356427, 31.22598039215686)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate MSE\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "mse_train, mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lakukan perulangan\n",
    "B = [10, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
    "mse_train_list = []\n",
    "mse_test_list = []\n",
    "\n",
    "for b in B:\n",
    "    # Buat bagging model\n",
    "    bagging_mdl = bagging(X_train = X_train_clean, \n",
    "                          y_train = y_train, \n",
    "                          B = b)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_train = predict_bagging(estimator = bagging_mdl,\n",
    "                                   X = X_train_clean)\n",
    "    y_pred_test = predict_bagging(estimator = bagging_mdl,\n",
    "                                  X = X_test_clean)\n",
    "\n",
    "    # Calculate mse\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "    # Append MSE\n",
    "    mse_train_list.append(mse_train)\n",
    "    mse_test_list.append(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 7))\n",
    "\n",
    "ax.plot(B, mse_train_list, \"b\", marker = \"o\", label = \"Train\")\n",
    "ax.plot(B, mse_test_list, \"r\", marker = \"x\", label = \"Test\")\n",
    "\n",
    "ax.set_xlabel(\"B\")\n",
    "ax.set_ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "Catatan! - Gambar di atas hanya menunjukkan kalau makin besar nilai B, model tidak akan overfit.\n",
    "\n",
    "Pemilihan model terbaik <b>tidak</b> dilakukan dengan melihat performa test, <b>namun</b> dengan melihat performa CV.\n",
    "</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with Sklearn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=DecisionTreeRegressor(), random_state=123)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base estimator\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "# Buat Bagging\n",
    "bagging_tree = BaggingRegressor(base_estimator = tree,\n",
    "                                n_estimators = 10,\n",
    "                                random_state = 123)\n",
    "\n",
    "# Fit bagging\n",
    "bagging_tree.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train :1.8884\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred_train = bagging_tree.predict(X_train_clean)\n",
    "\n",
    "# MSE\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "print(f\"MSE Train :{mse_train:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lakukan gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"n_estimators\": B}\n",
    "\n",
    "# Buat gridsearch\n",
    "tree = DecisionTreeRegressor()\n",
    "bagging_tree = BaggingRegressor(base_estimator = tree,\n",
    "                                random_state = 123)\n",
    "\n",
    "bagging_cv = GridSearchCV(estimator = bagging_tree,\n",
    "                          param_grid = params,\n",
    "                          cv = 5,\n",
    "                          scoring = \"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=BaggingRegressor(base_estimator=DecisionTreeRegressor(),\n",
       "                                        random_state=123),\n",
       "             param_grid={'n_estimators': [10, 50, 100, 150, 200, 250, 300, 350,\n",
       "                                          400, 450, 500]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit grid search cv\n",
    "bagging_cv.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best params\n",
    "bagging_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_estimators=500,\n",
       "                 random_state=123)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit the bagging tree\n",
    "bagging_tree = BaggingRegressor(base_estimator = tree,\n",
    "                                n_estimators = bagging_cv.best_params_[\"n_estimators\"],\n",
    "                                random_state = 123)\n",
    "\n",
    "bagging_tree.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train :1.4669\n",
      "MSE CV    :11.5832\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred_train = bagging_tree.predict(X_train_clean)\n",
    "\n",
    "# MSE\n",
    "mse_train_bg = mean_squared_error(y_train, y_pred_train)\n",
    "mse_cv_bg = -bagging_cv.best_score_\n",
    "\n",
    "print(f\"MSE Train :{mse_train_bg:.4f}\")\n",
    "print(f\"MSE CV    :{mse_cv_bg:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Random Forest Method\n",
    "1. Membuat $B$-sampel bootstrap\n",
    "2. Menentukan $p$ fitur yang digunakan untuk membuat model Decision Tree\n",
    "3. Membuat $B$-model decision tree untuk masing-masing sampel\n",
    "4. Setiap model melakukan prediksi.\n",
    "5. Melakukan agregasi dari setiap hasil prediksi.\n",
    "    - Regresi menggunakan rata-rata\n",
    "    - Klasifikasi menggunakan majority vote"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build random forest\n",
    "rf_tree = RandomForestRegressor(n_estimators = 100,\n",
    "                                criterion = \"squared_error\",\n",
    "                                max_features = \"sqrt\",\n",
    "                                random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features='sqrt', random_state=123)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit random forest\n",
    "rf_tree.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3711730643564315, 13.106767980392158)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred_train = rf_tree.predict(X_train_clean)\n",
    "y_pred_test = rf_tree.predict(X_test_clean)\n",
    "\n",
    "# MSE\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "mse_train, mse_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lakukan gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"n_estimators\": B,\n",
    "          \"max_features\": [\"sqrt\", \"log2\"]}\n",
    "\n",
    "# Buat gridsearch\n",
    "rf_tree = RandomForestRegressor(criterion = \"squared_error\",\n",
    "                                random_state = 123)\n",
    "\n",
    "rf_tree_cv = GridSearchCV(estimator = rf_tree,\n",
    "                          param_grid = params,\n",
    "                          cv = 5,\n",
    "                          scoring = \"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=123),\n",
       "             param_grid={'max_features': ['sqrt', 'log2'],\n",
       "                         'n_estimators': [10, 50, 100, 150, 200, 250, 300, 350,\n",
       "                                          400, 450, 500]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit grid search cv\n",
    "rf_tree_cv.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'sqrt', 'n_estimators': 100}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best params\n",
    "rf_tree_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features='sqrt', random_state=123)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit the Random Forest\n",
    "rf_tree = RandomForestRegressor(criterion = \"squared_error\",\n",
    "                                max_features = rf_tree_cv.best_params_[\"max_features\"],\n",
    "                                n_estimators = rf_tree_cv.best_params_[\"n_estimators\"],\n",
    "                                random_state = 123)\n",
    "\n",
    "rf_tree.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train :1.3712\n",
      "MSE CV    :10.8384\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred_train = rf_tree.predict(X_train_clean)\n",
    "\n",
    "# MSE\n",
    "mse_train_rf = mean_squared_error(y_train, y_pred_train)\n",
    "mse_cv_rf = -rf_tree_cv.best_score_\n",
    "\n",
    "print(f\"MSE Train :{mse_train_rf:.4f}\")\n",
    "print(f\"MSE CV    :{mse_cv_rf:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Adaboost Method\n",
    "1. Set weight data sama\n",
    "2. Bootstrap data\n",
    "3. Buat simple decision tree (Stomps / weak learner) -- decision tree dengan 1 atau 2 split\n",
    "4. Fit decision tree ke data\n",
    "5. Predict error dari hasil fitting\n",
    "6. Atur ulang weight (menggunakan formula di slide)\n",
    "7. Ulangi kembali langkah 2-6 untuk n-estimators\n",
    "8. Hasil prediksi adalah jumlah berbobot dari prediksi weak learner yang dikumpulkan\n",
    "\n",
    "\n",
    "with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build random forest\n",
    "tree = DecisionTreeRegressor(max_depth = 3)\n",
    "ada_tree = AdaBoostRegressor(base_estimator = tree,\n",
    "                             n_estimators = 50,\n",
    "                             random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=3),\n",
       "                  random_state=123)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit random forest\n",
    "ada_tree.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.1322085405817415, 15.42782126383905)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred_train = ada_tree.predict(X_train_clean)\n",
    "y_pred_test = ada_tree.predict(X_test_clean)\n",
    "\n",
    "# MSE\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "mse_train, mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lakukan gridsearch\n",
    "\n",
    "params = {\"n_estimators\": B}\n",
    "\n",
    "# Buat gridsearch\n",
    "tree = DecisionTreeRegressor(max_depth = 3)\n",
    "ada_tree = AdaBoostRegressor(base_estimator = tree,\n",
    "                             random_state = 123)\n",
    "\n",
    "ada_tree_cv = GridSearchCV(estimator = ada_tree,\n",
    "                           param_grid = params,\n",
    "                           cv = 5,\n",
    "                           scoring = \"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=3),\n",
       "                                         random_state=123),\n",
       "             param_grid={'n_estimators': [10, 50, 100, 150, 200, 250, 300, 350,\n",
       "                                          400, 450, 500]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit grid search cv\n",
    "ada_tree_cv.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best params\n",
    "ada_tree_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=3),\n",
       "                  n_estimators=500, random_state=123)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit the Adaboost\n",
    "tree = DecisionTreeRegressor(max_depth = 3)\n",
    "ada_tree = AdaBoostRegressor(base_estimator = tree,\n",
    "                             n_estimators = ada_tree_cv.best_params_[\"n_estimators\"],\n",
    "                             random_state = 123)\n",
    "\n",
    "ada_tree.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train :6.7723\n",
      "MSE CV    :14.3213\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred_train = ada_tree.predict(X_train_clean)\n",
    "\n",
    "# MSE\n",
    "mse_train_ab = mean_squared_error(y_train, y_pred_train)\n",
    "mse_cv_ab = -ada_tree_cv.best_score_\n",
    "\n",
    "print(f\"MSE Train :{mse_train_ab:.4f}\")\n",
    "print(f\"MSE CV    :{mse_cv_ab:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Better Version of Boosting - Gradient Boosting Method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*with sklearn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build random forest\n",
    "grad_tree = GradientBoostingRegressor(random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=123)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit random forest\n",
    "grad_tree.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.737324121513029, 15.732049218921901)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred_train = grad_tree.predict(X_train_clean)\n",
    "y_pred_test = grad_tree.predict(X_test_clean)\n",
    "\n",
    "# MSE\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "mse_train, mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lakukan gridsearch\n",
    "\n",
    "params = {\"n_estimators\": B}\n",
    "\n",
    "# Buat gridsearch\n",
    "grad_tree = GradientBoostingRegressor(random_state = 123)\n",
    "\n",
    "grad_tree_cv = GridSearchCV(estimator = grad_tree,\n",
    "                           param_grid = params,\n",
    "                           cv = 5,\n",
    "                           scoring = \"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(random_state=123),\n",
       "             param_grid={'n_estimators': [10, 50, 100, 150, 200, 250, 300, 350,\n",
       "                                          400, 450, 500]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit grid search cv\n",
    "grad_tree_cv.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best params\n",
    "grad_tree_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(n_estimators=200, random_state=123)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit the Adaboost\n",
    "grad_tree = GradientBoostingRegressor(n_estimators = grad_tree_cv.best_params_[\"n_estimators\"],\n",
    "                                      random_state = 123)\n",
    "\n",
    "grad_tree.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train :0.6686\n",
      "MSE CV    :10.3065\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred_train = grad_tree.predict(X_train_clean)\n",
    "\n",
    "# MSE\n",
    "mse_train_gb = mean_squared_error(y_train, y_pred_train)\n",
    "mse_cv_gb = -grad_tree_cv.best_score_\n",
    "\n",
    "print(f\"MSE Train :{mse_train_gb:.4f}\")\n",
    "print(f\"MSE CV    :{mse_cv_gb:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE Train</th>\n",
       "      <th>MSE CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>9.661235</td>\n",
       "      <td>25.106863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging</th>\n",
       "      <td>1.466881</td>\n",
       "      <td>11.583174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>1.371173</td>\n",
       "      <td>10.838444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaBoost</th>\n",
       "      <td>6.772296</td>\n",
       "      <td>14.321322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradientBoost</th>\n",
       "      <td>0.668642</td>\n",
       "      <td>10.306474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MSE Train     MSE CV\n",
       "decision tree   9.661235  25.106863\n",
       "bagging         1.466881  11.583174\n",
       "random forest   1.371173  10.838444\n",
       "adaBoost        6.772296  14.321322\n",
       "gradientBoost   0.668642  10.306474"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_train = [mse_train_dt, mse_train_bg, mse_train_rf, mse_train_ab, mse_train_gb]\n",
    "mse_cv = [mse_cv_dt, mse_cv_bg, mse_cv_rf, mse_cv_ab, mse_cv_gb]\n",
    "indexes = [\"decision tree\", \"bagging\", \"random forest\", \"adaBoost\", \"gradientBoost\"]\n",
    "\n",
    "summary_df = pd.DataFrame({\"MSE Train\": mse_train,\n",
    "                           \"MSE CV\": mse_cv},\n",
    "                          index = indexes)\n",
    "summary_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Best Model\n",
    "\n",
    "**Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16.599354715236913, 83.35052289664024)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict MSE\n",
    "y_pred_test = grad_tree.predict(X_test_clean)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "mse_test, mse_test_baseline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
